{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Physician Compare National: Explore #12_\n",
    "\n",
    "This notebook is a continuation from of my analysis on the following data gathered via [Data.Medicare.gov](https://data.medicare.gov/Physician-Compare/Physician-Compare-National-Downloadable-File/mj5m-pzi6). It contains general information about individual eligible professionals (EPs) such as demographic information and Medicare quality program participation. This dataset is updated twice a month with the most current demographic information available at that time.\n",
    "\n",
    "# _Today's Goal(s)_\n",
    "\n",
    "This isn't my primary focus today; I would like to continue my work with the Twitter project. However, based on the last test of the `zip_generator` function in the `explore-11` Jupyter notebook, it looks like the function might be ready for prime-time. This will be the first trial on the entire physician compare dataset of ~2.21M rows of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work started:  2019-10-14 11:45:55.567409\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# timestamp to signify the beginning of work\n",
    "print(\"Work started: \", now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npi</th>\n",
       "      <th>ind_pac_id</th>\n",
       "      <th>ind_enrl_id</th>\n",
       "      <th>full_nm</th>\n",
       "      <th>gndr</th>\n",
       "      <th>cred</th>\n",
       "      <th>med_sch</th>\n",
       "      <th>grd_yr</th>\n",
       "      <th>pri_spec</th>\n",
       "      <th>sec_spec_1</th>\n",
       "      <th>sec_spec_2</th>\n",
       "      <th>sec_spec_3</th>\n",
       "      <th>sec_spec_4</th>\n",
       "      <th>sec_spec_all</th>\n",
       "      <th>org_lgl_nm</th>\n",
       "      <th>org_pac_id</th>\n",
       "      <th>num_org_mem</th>\n",
       "      <th>full_adr</th>\n",
       "      <th>ln_2_sprs</th>\n",
       "      <th>cty</th>\n",
       "      <th>st</th>\n",
       "      <th>zip</th>\n",
       "      <th>phn_numbr</th>\n",
       "      <th>hosp_afl_1</th>\n",
       "      <th>hosp_afl_lbn_1</th>\n",
       "      <th>hosp_afl_2</th>\n",
       "      <th>hosp_afl_lbn_2</th>\n",
       "      <th>hosp_afl_3</th>\n",
       "      <th>hosp_afl_lbn_3</th>\n",
       "      <th>hosp_afl_4</th>\n",
       "      <th>hosp_afl_lbn_4</th>\n",
       "      <th>hosp_afl_5</th>\n",
       "      <th>hosp_afl_lbn_5</th>\n",
       "      <th>assgn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>7517003643</td>\n",
       "      <td>I20130530000085</td>\n",
       "      <td>ARDALAN  ENKESHAFI</td>\n",
       "      <td>M</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1994</td>\n",
       "      <td>INTERNAL MEDICINE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>EMERGENCY MEDICINE ASSOCIATES PA PC</td>\n",
       "      <td>8.022915e+09</td>\n",
       "      <td>182</td>\n",
       "      <td>1850 TOWN CTR PKWY</td>\n",
       "      <td>N</td>\n",
       "      <td>RESTON</td>\n",
       "      <td>VA</td>\n",
       "      <td>201903219</td>\n",
       "      <td>7.036899e+09</td>\n",
       "      <td>490112.0</td>\n",
       "      <td>CJW MEDICAL CENTER</td>\n",
       "      <td>210028.0</td>\n",
       "      <td>MEDSTAR SAINT MARY'S HOSPITAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>7517003643</td>\n",
       "      <td>I20130530000085</td>\n",
       "      <td>ARDALAN  ENKESHAFI</td>\n",
       "      <td>M</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1994</td>\n",
       "      <td>INTERNAL MEDICINE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>EMERGENCY MEDICINE ASSOCIATES PA PC</td>\n",
       "      <td>8.022915e+09</td>\n",
       "      <td>182</td>\n",
       "      <td>1701 N GEORGE MASON DR</td>\n",
       "      <td>N</td>\n",
       "      <td>ARLINGTON</td>\n",
       "      <td>VA</td>\n",
       "      <td>222053610</td>\n",
       "      <td>7.035586e+09</td>\n",
       "      <td>490112.0</td>\n",
       "      <td>CJW MEDICAL CENTER</td>\n",
       "      <td>210028.0</td>\n",
       "      <td>MEDSTAR SAINT MARY'S HOSPITAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>7517003643</td>\n",
       "      <td>I20150824000105</td>\n",
       "      <td>ARDALAN  ENKESHAFI</td>\n",
       "      <td>M</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1994</td>\n",
       "      <td>INTERNAL MEDICINE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>EMERGENCY MEDICINE ASSOCIATES PA PC</td>\n",
       "      <td>8.022915e+09</td>\n",
       "      <td>182</td>\n",
       "      <td>24440 STONE SPRINGS BLVD</td>\n",
       "      <td>N</td>\n",
       "      <td>DULLES</td>\n",
       "      <td>VA</td>\n",
       "      <td>201662247</td>\n",
       "      <td>5.713674e+09</td>\n",
       "      <td>490112.0</td>\n",
       "      <td>CJW MEDICAL CENTER</td>\n",
       "      <td>210028.0</td>\n",
       "      <td>MEDSTAR SAINT MARY'S HOSPITAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>7517003643</td>\n",
       "      <td>I20150824000105</td>\n",
       "      <td>ARDALAN  ENKESHAFI</td>\n",
       "      <td>M</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1994</td>\n",
       "      <td>INTERNAL MEDICINE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SOUTHEASTERN INTENSIVIST SERVICES PC</td>\n",
       "      <td>9.335152e+09</td>\n",
       "      <td>133</td>\n",
       "      <td>1401 JOHNSTON WILLIS DR</td>\n",
       "      <td>N</td>\n",
       "      <td>NORTH CHESTERFIELD</td>\n",
       "      <td>VA</td>\n",
       "      <td>232354730</td>\n",
       "      <td>8.044835e+09</td>\n",
       "      <td>490112.0</td>\n",
       "      <td>CJW MEDICAL CENTER</td>\n",
       "      <td>210028.0</td>\n",
       "      <td>MEDSTAR SAINT MARY'S HOSPITAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>7517003643</td>\n",
       "      <td>I20150824000105</td>\n",
       "      <td>ARDALAN  ENKESHAFI</td>\n",
       "      <td>M</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1994</td>\n",
       "      <td>INTERNAL MEDICINE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>SOUTHEASTERN INTENSIVIST SERVICES PC</td>\n",
       "      <td>9.335152e+09</td>\n",
       "      <td>133</td>\n",
       "      <td>411 W RANDOLPH RD</td>\n",
       "      <td>N</td>\n",
       "      <td>HOPEWELL</td>\n",
       "      <td>VA</td>\n",
       "      <td>238602938</td>\n",
       "      <td>8.045412e+09</td>\n",
       "      <td>490112.0</td>\n",
       "      <td>CJW MEDICAL CENTER</td>\n",
       "      <td>210028.0</td>\n",
       "      <td>MEDSTAR SAINT MARY'S HOSPITAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          npi  ind_pac_id      ind_enrl_id              full_nm gndr  \\\n",
       "0  1003000126  7517003643  I20130530000085  ARDALAN  ENKESHAFI     M   \n",
       "1  1003000126  7517003643  I20130530000085  ARDALAN  ENKESHAFI     M   \n",
       "2  1003000126  7517003643  I20150824000105  ARDALAN  ENKESHAFI     M   \n",
       "3  1003000126  7517003643  I20150824000105  ARDALAN  ENKESHAFI     M   \n",
       "4  1003000126  7517003643  I20150824000105  ARDALAN  ENKESHAFI     M   \n",
       "\n",
       "         cred med_sch  grd_yr           pri_spec sec_spec_1 sec_spec_2  \\\n",
       "0  Not Listed   OTHER    1994  INTERNAL MEDICINE       None       None   \n",
       "1  Not Listed   OTHER    1994  INTERNAL MEDICINE       None       None   \n",
       "2  Not Listed   OTHER    1994  INTERNAL MEDICINE       None       None   \n",
       "3  Not Listed   OTHER    1994  INTERNAL MEDICINE       None       None   \n",
       "4  Not Listed   OTHER    1994  INTERNAL MEDICINE       None       None   \n",
       "\n",
       "  sec_spec_3 sec_spec_4 sec_spec_all                            org_lgl_nm  \\\n",
       "0       None       None         None   EMERGENCY MEDICINE ASSOCIATES PA PC   \n",
       "1       None       None         None   EMERGENCY MEDICINE ASSOCIATES PA PC   \n",
       "2       None       None         None   EMERGENCY MEDICINE ASSOCIATES PA PC   \n",
       "3       None       None         None  SOUTHEASTERN INTENSIVIST SERVICES PC   \n",
       "4       None       None         None  SOUTHEASTERN INTENSIVIST SERVICES PC   \n",
       "\n",
       "     org_pac_id  num_org_mem                   full_adr ln_2_sprs  \\\n",
       "0  8.022915e+09          182        1850 TOWN CTR PKWY          N   \n",
       "1  8.022915e+09          182    1701 N GEORGE MASON DR          N   \n",
       "2  8.022915e+09          182  24440 STONE SPRINGS BLVD          N   \n",
       "3  9.335152e+09          133   1401 JOHNSTON WILLIS DR          N   \n",
       "4  9.335152e+09          133         411 W RANDOLPH RD          N   \n",
       "\n",
       "                  cty  st        zip     phn_numbr hosp_afl_1  \\\n",
       "0              RESTON  VA  201903219  7.036899e+09   490112.0   \n",
       "1           ARLINGTON  VA  222053610  7.035586e+09   490112.0   \n",
       "2              DULLES  VA  201662247  5.713674e+09   490112.0   \n",
       "3  NORTH CHESTERFIELD  VA  232354730  8.044835e+09   490112.0   \n",
       "4            HOPEWELL  VA  238602938  8.045412e+09   490112.0   \n",
       "\n",
       "       hosp_afl_lbn_1 hosp_afl_2                 hosp_afl_lbn_2 hosp_afl_3  \\\n",
       "0  CJW MEDICAL CENTER   210028.0  MEDSTAR SAINT MARY'S HOSPITAL        NaN   \n",
       "1  CJW MEDICAL CENTER   210028.0  MEDSTAR SAINT MARY'S HOSPITAL        NaN   \n",
       "2  CJW MEDICAL CENTER   210028.0  MEDSTAR SAINT MARY'S HOSPITAL        NaN   \n",
       "3  CJW MEDICAL CENTER   210028.0  MEDSTAR SAINT MARY'S HOSPITAL        NaN   \n",
       "4  CJW MEDICAL CENTER   210028.0  MEDSTAR SAINT MARY'S HOSPITAL        NaN   \n",
       "\n",
       "  hosp_afl_lbn_3 hosp_afl_4 hosp_afl_lbn_4  hosp_afl_5 hosp_afl_lbn_5 assgn  \n",
       "0            NaN        NaN            NaN         NaN            NaN     Y  \n",
       "1            NaN        NaN            NaN         NaN            NaN     Y  \n",
       "2            NaN        NaN            NaN         NaN            NaN     Y  \n",
       "3            NaN        NaN            NaN         NaN            NaN     Y  \n",
       "4            NaN        NaN            NaN         NaN            NaN     Y  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first thing we need to do --> load in the data\n",
    "# import pandas\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import data from yesterday\n",
    "data = pd.read_csv('physician_compare_national-updates-2.csv', low_memory=False);\n",
    "\n",
    "# inspect the first five rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Drop Observations Not Located in one of the 50 states_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store indexes\n",
    "drop_index = []\n",
    "\n",
    "# loop through state abbreviations of locations that aren't one of the 50 states\n",
    "for val in ['PR', 'GU', 'VI', 'MP']:\n",
    "    # gather indexs of observations with val\n",
    "    indexes = list(data[data['st'] == val].index)\n",
    "    drop_index.append(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how long is the drop_index list?\n",
    "len(drop_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[251, 252, 271, 682, 959]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract first five indexes from first list in drop_index\n",
    "drop_index[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since drop_index is a list of lists, lets flatten it then sort it by the values\n",
    "flat_index = [item for sublist in drop_index for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7169"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how long is our flattened list?\n",
    "len(flat_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[251, 252, 271, 682, 959, 1882, 2278, 2279, 2468, 2717]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at the first few observations\n",
    "flat_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[251, 252, 271, 682, 959, 1882, 2278, 2279, 2468, 2717]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to sort flat_index\n",
    "flat_index = sorted(flat_index); flat_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA    182214\n",
       "NY    147143\n",
       "TX    141947\n",
       "FL    122414\n",
       "PA    118094\n",
       "MI    104868\n",
       "IL     93257\n",
       "OH     88951\n",
       "NC     81437\n",
       "MA     67807\n",
       "WI     64466\n",
       "MN     63019\n",
       "NJ     59030\n",
       "GA     56316\n",
       "WA     55258\n",
       "VA     53381\n",
       "IN     49461\n",
       "MD     48677\n",
       "TN     44113\n",
       "MO     42797\n",
       "AZ     41899\n",
       "CO     37223\n",
       "KY     31497\n",
       "OR     30908\n",
       "CT     30019\n",
       "SC     28161\n",
       "LA     26278\n",
       "IA     23996\n",
       "AL     23056\n",
       "KS     21571\n",
       "OK     20610\n",
       "UT     18180\n",
       "MS     15990\n",
       "ME     14378\n",
       "AR     14080\n",
       "NE     13699\n",
       "ID     13094\n",
       "NV     11747\n",
       "WV     11691\n",
       "NH     11608\n",
       "NM     11418\n",
       "DE      9656\n",
       "RI      8133\n",
       "SD      8062\n",
       "MT      7739\n",
       "ND      7286\n",
       "HI      6986\n",
       "DC      6151\n",
       "AK      5139\n",
       "VT      5077\n",
       "WY      3639\n",
       "Name: st, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with our list of indexes, let's drop these observations\n",
    "data.drop(flat_index)['st'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique values are in the state column once we drop according to flat_index?\n",
    "len(data.drop(flat_index)['st'].astype(str).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Lets apply this now to our `data` DataFrame, after which we can apply our zipcode function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop indexes with state abbreviations we're not focused on\n",
    "data2 = data.drop(flat_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Insert (& Clean) `full_location` column_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 369 ms, sys: 93.8 ms, total: 463 ms\n",
      "Wall time: 627 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create full_location by combining cty and st\n",
    "full_location = data2['cty'] + ', ' + data2['st']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column index: 0 Column name: npi\n",
      "Column index: 1 Column name: ind_pac_id\n",
      "Column index: 2 Column name: ind_enrl_id\n",
      "Column index: 3 Column name: full_nm\n",
      "Column index: 4 Column name: gndr\n",
      "Column index: 5 Column name: cred\n",
      "Column index: 6 Column name: med_sch\n",
      "Column index: 7 Column name: grd_yr\n",
      "Column index: 8 Column name: pri_spec\n",
      "Column index: 9 Column name: sec_spec_1\n",
      "Column index: 10 Column name: sec_spec_2\n",
      "Column index: 11 Column name: sec_spec_3\n",
      "Column index: 12 Column name: sec_spec_4\n",
      "Column index: 13 Column name: sec_spec_all\n",
      "Column index: 14 Column name: org_lgl_nm\n",
      "Column index: 15 Column name: org_pac_id\n",
      "Column index: 16 Column name: num_org_mem\n",
      "Column index: 17 Column name: full_adr\n",
      "Column index: 18 Column name: ln_2_sprs\n",
      "Column index: 19 Column name: cty\n",
      "Column index: 20 Column name: st\n",
      "Column index: 21 Column name: zip\n",
      "Column index: 22 Column name: phn_numbr\n",
      "Column index: 23 Column name: hosp_afl_1\n",
      "Column index: 24 Column name: hosp_afl_lbn_1\n",
      "Column index: 25 Column name: hosp_afl_2\n",
      "Column index: 26 Column name: hosp_afl_lbn_2\n",
      "Column index: 27 Column name: hosp_afl_3\n",
      "Column index: 28 Column name: hosp_afl_lbn_3\n",
      "Column index: 29 Column name: hosp_afl_4\n",
      "Column index: 30 Column name: hosp_afl_lbn_4\n",
      "Column index: 31 Column name: hosp_afl_5\n",
      "Column index: 32 Column name: hosp_afl_lbn_5\n",
      "Column index: 33 Column name: assgn\n"
     ]
    }
   ],
   "source": [
    "# print out the columns and their associated index\n",
    "for i, v in enumerate(list(data2.columns)):\n",
    "    print('Column index: {} Column name: {}'.format(i, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert full location after st column (index = 21)\n",
    "data2.insert(loc=21, column='full_location', value=full_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npi</th>\n",
       "      <th>ind_pac_id</th>\n",
       "      <th>ind_enrl_id</th>\n",
       "      <th>full_nm</th>\n",
       "      <th>gndr</th>\n",
       "      <th>cred</th>\n",
       "      <th>med_sch</th>\n",
       "      <th>grd_yr</th>\n",
       "      <th>pri_spec</th>\n",
       "      <th>sec_spec_1</th>\n",
       "      <th>sec_spec_2</th>\n",
       "      <th>sec_spec_3</th>\n",
       "      <th>sec_spec_4</th>\n",
       "      <th>sec_spec_all</th>\n",
       "      <th>org_lgl_nm</th>\n",
       "      <th>org_pac_id</th>\n",
       "      <th>num_org_mem</th>\n",
       "      <th>full_adr</th>\n",
       "      <th>ln_2_sprs</th>\n",
       "      <th>cty</th>\n",
       "      <th>st</th>\n",
       "      <th>full_location</th>\n",
       "      <th>zip</th>\n",
       "      <th>phn_numbr</th>\n",
       "      <th>hosp_afl_1</th>\n",
       "      <th>hosp_afl_lbn_1</th>\n",
       "      <th>hosp_afl_2</th>\n",
       "      <th>hosp_afl_lbn_2</th>\n",
       "      <th>hosp_afl_3</th>\n",
       "      <th>hosp_afl_lbn_3</th>\n",
       "      <th>hosp_afl_4</th>\n",
       "      <th>hosp_afl_lbn_4</th>\n",
       "      <th>hosp_afl_5</th>\n",
       "      <th>hosp_afl_lbn_5</th>\n",
       "      <th>assgn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>7517003643</td>\n",
       "      <td>I20130530000085</td>\n",
       "      <td>ARDALAN  ENKESHAFI</td>\n",
       "      <td>M</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1994</td>\n",
       "      <td>INTERNAL MEDICINE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>EMERGENCY MEDICINE ASSOCIATES PA PC</td>\n",
       "      <td>8.022915e+09</td>\n",
       "      <td>182</td>\n",
       "      <td>1850 TOWN CTR PKWY</td>\n",
       "      <td>N</td>\n",
       "      <td>RESTON</td>\n",
       "      <td>VA</td>\n",
       "      <td>RESTON, VA</td>\n",
       "      <td>201903219</td>\n",
       "      <td>7.036899e+09</td>\n",
       "      <td>490112.0</td>\n",
       "      <td>CJW MEDICAL CENTER</td>\n",
       "      <td>210028.0</td>\n",
       "      <td>MEDSTAR SAINT MARY'S HOSPITAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>7517003643</td>\n",
       "      <td>I20130530000085</td>\n",
       "      <td>ARDALAN  ENKESHAFI</td>\n",
       "      <td>M</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1994</td>\n",
       "      <td>INTERNAL MEDICINE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>EMERGENCY MEDICINE ASSOCIATES PA PC</td>\n",
       "      <td>8.022915e+09</td>\n",
       "      <td>182</td>\n",
       "      <td>1701 N GEORGE MASON DR</td>\n",
       "      <td>N</td>\n",
       "      <td>ARLINGTON</td>\n",
       "      <td>VA</td>\n",
       "      <td>ARLINGTON, VA</td>\n",
       "      <td>222053610</td>\n",
       "      <td>7.035586e+09</td>\n",
       "      <td>490112.0</td>\n",
       "      <td>CJW MEDICAL CENTER</td>\n",
       "      <td>210028.0</td>\n",
       "      <td>MEDSTAR SAINT MARY'S HOSPITAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          npi  ind_pac_id      ind_enrl_id              full_nm gndr  \\\n",
       "0  1003000126  7517003643  I20130530000085  ARDALAN  ENKESHAFI     M   \n",
       "1  1003000126  7517003643  I20130530000085  ARDALAN  ENKESHAFI     M   \n",
       "\n",
       "         cred med_sch  grd_yr           pri_spec sec_spec_1 sec_spec_2  \\\n",
       "0  Not Listed   OTHER    1994  INTERNAL MEDICINE       None       None   \n",
       "1  Not Listed   OTHER    1994  INTERNAL MEDICINE       None       None   \n",
       "\n",
       "  sec_spec_3 sec_spec_4 sec_spec_all                           org_lgl_nm  \\\n",
       "0       None       None         None  EMERGENCY MEDICINE ASSOCIATES PA PC   \n",
       "1       None       None         None  EMERGENCY MEDICINE ASSOCIATES PA PC   \n",
       "\n",
       "     org_pac_id  num_org_mem                 full_adr ln_2_sprs        cty  \\\n",
       "0  8.022915e+09          182      1850 TOWN CTR PKWY          N     RESTON   \n",
       "1  8.022915e+09          182  1701 N GEORGE MASON DR          N  ARLINGTON   \n",
       "\n",
       "   st  full_location        zip     phn_numbr hosp_afl_1      hosp_afl_lbn_1  \\\n",
       "0  VA     RESTON, VA  201903219  7.036899e+09   490112.0  CJW MEDICAL CENTER   \n",
       "1  VA  ARLINGTON, VA  222053610  7.035586e+09   490112.0  CJW MEDICAL CENTER   \n",
       "\n",
       "  hosp_afl_2                 hosp_afl_lbn_2 hosp_afl_3 hosp_afl_lbn_3  \\\n",
       "0   210028.0  MEDSTAR SAINT MARY'S HOSPITAL        NaN            NaN   \n",
       "1   210028.0  MEDSTAR SAINT MARY'S HOSPITAL        NaN            NaN   \n",
       "\n",
       "  hosp_afl_4 hosp_afl_lbn_4  hosp_afl_5 hosp_afl_lbn_5 assgn  \n",
       "0        NaN            NaN         NaN            NaN     Y  \n",
       "1        NaN            NaN         NaN            NaN     Y  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if insertion worked\n",
    "data2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've inserted the `full_location` column, we need to clean it up a little bit. As you will see below, the combining of the columns didn't work for some of the observations because there were typos in the original columns (i.e. `cty` and `st`). We discovered this in our previous notebook and will address and update the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KITTERY, ME 03904, ME'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of a full_location with typo\n",
    "data2.loc[286572, 'full_location']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to import the `re` library which will help us deal with the strings in this column. Below is an example of `re`'s `findall` function, which in this case looks for all the commas in `full_location` column for the observation at index `286572`. As we can see from the output above, it correctly outputs two commas in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', ',']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re.findall(r',', data2.loc[286572, 'full_location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the tools necessary, lets loop through this whole column and see where there are other 'messy' `full_location` entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full location with at least two commas found at 111125\n",
      "Full location with at least two commas found at 267029\n",
      "Full location with at least two commas found at 286572\n",
      "Full location with at least two commas found at 332637\n",
      "Full location with at least two commas found at 415837\n",
      "Full location with at least two commas found at 840123\n",
      "Full location with at least two commas found at 920591\n",
      "Full location with at least two commas found at 1059997\n",
      "Full location with at least two commas found at 1135187\n",
      "Full location with at least two commas found at 1238978\n",
      "Full location with at least two commas found at 1551245\n",
      "Full location with at least two commas found at 1645471\n",
      "Full location with at least two commas found at 1705880\n",
      "Full location with at least two commas found at 1812563\n",
      "Full location with at least two commas found at 1820194\n",
      "Full location with at least two commas found at 2024083\n",
      "Full location with at least two commas found at 2158428\n",
      "Full location with at least two commas found at 2195532\n",
      "CPU times: user 3min 15s, sys: 2.3 s, total: 3min 17s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for loop that will check for other observations that have 2 or more commas\n",
    "for index, row in data2.iterrows():\n",
    "    comma_check = re.findall(r',', row['full_location'])\n",
    "    if len(comma_check) >= 2:\n",
    "        print('Full location with at least two commas found at {}'.format(index))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have a few typos to address; instead of entering in the indexes manually, let's do the same loop as above but with a slight tweak. We'll append these index values to a list so that it makes it a little easier to look them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full location with at least two commas found at 111125\n",
      "Full location with at least two commas found at 267029\n",
      "Full location with at least two commas found at 286572\n",
      "Full location with at least two commas found at 332637\n",
      "Full location with at least two commas found at 415837\n",
      "Full location with at least two commas found at 840123\n",
      "Full location with at least two commas found at 920591\n",
      "Full location with at least two commas found at 1059997\n",
      "Full location with at least two commas found at 1135187\n",
      "Full location with at least two commas found at 1238978\n",
      "Full location with at least two commas found at 1551245\n",
      "Full location with at least two commas found at 1645471\n",
      "Full location with at least two commas found at 1705880\n",
      "Full location with at least two commas found at 1812563\n",
      "Full location with at least two commas found at 1820194\n",
      "Full location with at least two commas found at 2024083\n",
      "Full location with at least two commas found at 2158428\n",
      "Full location with at least two commas found at 2195532\n",
      "CPU times: user 3min 12s, sys: 2.3 s, total: 3min 14s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# empty list to store indexes with more than 2 commas\n",
    "commas2 = []\n",
    "\n",
    "# for loop that will check for other observations that have 2 or more commas\n",
    "for index, row in data2.iterrows():\n",
    "    comma_check = re.findall(r',', row['full_location'])\n",
    "    if len(comma_check) >= 2:\n",
    "        commas2.append(index)\n",
    "        print('Full location with at least two commas found at {}'.format(index))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONROE, LA, LA\n",
      "VALLEY STREAM, NY, NY\n",
      "KITTERY, ME 03904, ME\n",
      "NEW YORK,, NY\n",
      "WASHINGTON, DC 20037, DC\n",
      "RINDGE, NH, NH\n",
      "CENTENNIAL,, CO\n",
      "NASHVILLE,, TN\n",
      "WASHINGTON, DC, DC\n",
      "RINDGE, NH, NH\n",
      "RIDGEWOOD, NEW JERSEY, NJ\n",
      "WEST CHESTER, OH, OH\n",
      "DESOTO, TX, TX\n",
      "MODESTO,, CA\n",
      "APOPKA,, FL\n",
      "NASHVILLE,, TN\n",
      "LITTLE ROCK, AR, AR\n",
      "ALEXANDRIA,, IN\n"
     ]
    }
   ],
   "source": [
    "# loop through and print out full location\n",
    "for idx in commas2:\n",
    "    print(data2['full_location'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONROE, LA\n",
      "VALLEY STREAM, NY\n",
      "KITTERY, ME\n",
      "NEW YORK, NY\n",
      "WASHINGTON, DC\n",
      "RINDGE, NH\n",
      "CENTENNIAL, CO\n",
      "NASHVILLE, TN\n",
      "WASHINGTON, DC\n",
      "RINDGE, NH\n",
      "RIDGEWOOD, NJ\n",
      "WEST CHESTER, OH\n",
      "DESOTO, TX\n",
      "MODESTO, CA\n",
      "APOPKA, FL\n",
      "NASHVILLE, TN\n",
      "LITTLE ROCK, AR\n",
      "ALEXANDRIA, IN\n"
     ]
    }
   ],
   "source": [
    "# loop through to test potential strategy to clean up full location\n",
    "for idx in commas2:\n",
    "    one, two, three = data2['full_location'][idx].split(',')\n",
    "    new_string = (one + ',' + three).strip()\n",
    "    print(new_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jai/anaconda3/envs/geography/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# for loop that splits tring on commas and then returns string in correct format\n",
    "for idx in commas2:\n",
    "    one, two, three = data2['full_location'][idx].split(',')\n",
    "    new_string = (one + ',' + three)\n",
    "    data2['full_location'][idx] = new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONROE, LA\n",
      "VALLEY STREAM, NY\n",
      "KITTERY, ME\n",
      "NEW YORK, NY\n",
      "WASHINGTON, DC\n",
      "RINDGE, NH\n",
      "CENTENNIAL, CO\n",
      "NASHVILLE, TN\n",
      "WASHINGTON, DC\n",
      "RINDGE, NH\n",
      "RIDGEWOOD, NJ\n",
      "WEST CHESTER, OH\n",
      "DESOTO, TX\n",
      "MODESTO, CA\n",
      "APOPKA, FL\n",
      "NASHVILLE, TN\n",
      "LITTLE ROCK, AR\n",
      "ALEXANDRIA, IN\n"
     ]
    }
   ],
   "source": [
    "# loop through values and see if full_locations were updated\n",
    "for idx in commas2:\n",
    "    print(data2['full_location'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONROE, LA\n",
      "VALLEY STREAM, NY\n",
      "KITTERY, ME 03904\n",
      "NEW YORK,\n",
      "WASHINGTON, DC 20037\n",
      "RINDGE, NH\n",
      "CENTENNIAL,\n",
      "NASHVILLE,\n",
      "WASHINGTON, DC\n",
      "RINDGE, NH\n",
      "RIDGEWOOD, NEW JERSEY\n",
      "WEST CHESTER, OH\n",
      "DESOTO, TX\n",
      "MODESTO,\n",
      "APOPKA,\n",
      "NASHVILLE,\n",
      "LITTLE ROCK, AR\n",
      "ALEXANDRIA,\n"
     ]
    }
   ],
   "source": [
    "# the issue stemmed from the value in the cty column, let's loop through those to see what they look like\n",
    "for idx in commas2:\n",
    "    print(data2['cty'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONROE  LA\n",
      "VALLEY STREAM  NY\n",
      "KITTERY  ME\n",
      "NEW YORK  NY\n",
      "WASHINGTON  DC\n",
      "RINDGE  NH\n",
      "CENTENNIAL  CO\n",
      "NASHVILLE  TN\n",
      "WASHINGTON  DC\n",
      "RINDGE  NH\n",
      "RIDGEWOOD  NJ\n",
      "WEST CHESTER  OH\n",
      "DESOTO  TX\n",
      "MODESTO  CA\n",
      "APOPKA  FL\n",
      "NASHVILLE  TN\n",
      "LITTLE ROCK  AR\n",
      "ALEXANDRIA  IN\n"
     ]
    }
   ],
   "source": [
    "# if we split on the comma, it should be pretty straightforward to extract the city and state\n",
    "for idx in commas2:\n",
    "    cty, st = data2['full_location'][idx].split(',')\n",
    "    print(cty, st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jai/anaconda3/envs/geography/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated cty column for index 111125\n",
      "Updated cty column for index 267029\n",
      "Updated cty column for index 286572\n",
      "Updated cty column for index 332637\n",
      "Updated cty column for index 415837\n",
      "Updated cty column for index 840123\n",
      "Updated cty column for index 920591\n",
      "Updated cty column for index 1059997\n",
      "Updated cty column for index 1135187\n",
      "Updated cty column for index 1238978\n",
      "Updated cty column for index 1551245\n",
      "Updated cty column for index 1645471\n",
      "Updated cty column for index 1705880\n",
      "Updated cty column for index 1812563\n",
      "Updated cty column for index 1820194\n",
      "Updated cty column for index 2024083\n",
      "Updated cty column for index 2158428\n",
      "Updated cty column for index 2195532\n"
     ]
    }
   ],
   "source": [
    "# apply the above function to our dataset\n",
    "for idx in commas2:\n",
    "    cty, st = data2['full_location'][idx].split(',')\n",
    "    data2['cty'][idx] = cty\n",
    "    print('Updated cty column for index {}'.format(idx));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONROE\n",
      "VALLEY STREAM\n",
      "KITTERY\n",
      "NEW YORK\n",
      "WASHINGTON\n",
      "RINDGE\n",
      "CENTENNIAL\n",
      "NASHVILLE\n",
      "WASHINGTON\n",
      "RINDGE\n",
      "RIDGEWOOD\n",
      "WEST CHESTER\n",
      "DESOTO\n",
      "MODESTO\n",
      "APOPKA\n",
      "NASHVILLE\n",
      "LITTLE ROCK\n",
      "ALEXANDRIA\n"
     ]
    }
   ],
   "source": [
    "# loop through cty observations to make sure they've been updated\n",
    "for idx in commas2:\n",
    "    print(data2['cty'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop that will check for other observations that have 2 or more commas (TO CONFIRM NO MORE)\n",
    "for index, row in data2.iterrows():\n",
    "    comma_check = re.findall(r',', row['full_location'])\n",
    "    if len(comma_check) >= 2:\n",
    "        print('Full location with at least two commas found at {}'.format(index))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Save Updates to New CSV file_\n",
    "\n",
    "We want to make the changes permanent so we'll save the current `data2` `pandas` DataFrame to a CSV so we can just load it in next time without having to go through the above steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data set to new CSV file\n",
    "data2.to_csv('physician_compare_national-updates-3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _`zip_generator` Function & Application_\n",
    "\n",
    "In a previous notebook we developed a `zip_generator` function that would go through and assess the `zip` code column. This column is critically important as it's crucial to have this right if we want to accurately graph the distribution of physicians. Let's define it below to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# first thing we need to do --> load in the data\n",
    "# import pandas\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import data from yesterday\n",
    "data2 = pd.read_csv('physician_compare_national-updates-3.csv', low_memory=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from uszipcode library its SearchEngine and zip code databases\n",
    "from uszipcode import SearchEngine, SimpleZipcode, Zipcode\n",
    "\n",
    "# initialize zip code search engine object\n",
    "search = SearchEngine()\n",
    "\n",
    "# function developed to generate zip codes in format best ready for analysis\n",
    "def zip_generator(row):\n",
    "    if len(row['zip']) == 9: # if the zip is 9 characters long (meaning it has a +4) we'll grab just the first five\n",
    "        return row['zip'][:5]\n",
    "        pass\n",
    "    elif len(row['zip']) == 5: # if the zip is 5 characters long, we'll leave as is\n",
    "        return row['zip']\n",
    "        pass\n",
    "    else: # for anything else we'll look up the zip code based on the city and state\n",
    "        # split observation into cty and st\n",
    "        cty, st = [x.strip() for x in row['full_location'].split(', ')]\n",
    "        # use searchengine to look up cty and state\n",
    "        lookup = search.by_city_and_state(city=cty, state=st)\n",
    "        if lookup == []:\n",
    "            return row['zip']\n",
    "        else:\n",
    "            zipcode = lookup[0].values()[0]\n",
    "            #time.sleep(random.uniform(0, 0.25))\n",
    "            return zipcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is going to take awhile; when I tested it on a 25% sample of the data, it took the above function a little over an hour to process the column so for the full data set, we're looking at a few hours unfortunately. However, I want to highlight that this is a necessary step as we want to ensure that our location data is as accurate as possible! This isn't to say that it's the most efficient method available but it is the most efficient one that we have available to us.\n",
    "\n",
    "So without further ado, let's apply it and see what happens!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _First Trial Run of `zip_generator` on entire dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 48min 44s, sys: 4min 19s, total: 3h 53min 3s\n",
      "Wall time: 3h 54min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# second test of zip_generator function\n",
    "data2['new_zipcode'] = data2.apply(lambda row: zip_generator(row), axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2201882\n",
       "8       1701\n",
       "4         36\n",
       "3          2\n",
       "Name: new_zipcode, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the value counts for the associated zip code lengths?\n",
    "data2['new_zipcode'].astype(str).str.len().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we've covered the vast majority of the observations! However, there still are a few edge cases we need to deal with. We'll address these in the next notebook though so lets be sure we save our updates to a new CSV so we don't have to wait ~4 hrs again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('physician_compare_national-updates-4.csv', index=False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
